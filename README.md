# Detector de PlÃ¡gio e ParÃ¡frase

Este projeto implementa um sistema para **comparar textos** por duas abordagens complementares:  
- **LÃ©xica** â€“ anÃ¡lise baseada em padrÃµes de palavras (TF-IDF e n-gramas).  
- **SemÃ¢ntica** â€“ anÃ¡lise baseada no significado (embeddings com `sentence-transformers`).  

O objetivo Ã© combinar essas anÃ¡lises para obter uma avaliaÃ§Ã£o robusta da similaridade textual, Ãºtil para detecÃ§Ã£o de plÃ¡gio, identificaÃ§Ã£o de parÃ¡frases e comparaÃ§Ã£o de conteÃºdos de domÃ­nio pÃºblico.  

O projeto foi pensado para rodar **tanto localmente quanto via Docker**, garantindo que o ambiente seja reprodutÃ­vel e que os resultados sejam consistentes.

---

## âœï¸ Como usar este repositÃ³rio

### ğŸ“¥ Copiar o repositÃ³rio para o seu computador
Primeiro, Ã© necessÃ¡rio copiar o repositÃ³rio. Depois, vocÃª pode escolher rodar **localmente** ou com **Docker**.

```bash
git clone https://github.com/ethelbeluzzi/detector-plagio-parafrase.git
cd detector-plagio-parafrase
```

---


### ğŸ“¥ Copiar o repositÃ³rio para o seu computador
Primeiro, Ã© necessÃ¡rio copiar o repositÃ³rio. Depois, vocÃª pode escolher rodar **localmente** ou com **Docker**.

```bash
git clone https://github.com/ethelbeluzzi/detector-plagio-parafrase.git
cd detector-plagio-parafrase
```

---

### ğŸ’» 1) Rodar localmente

*Criar ambiente virtual:*
```bash
python -m venv .venv
```

*Ativar ambiente virtual:*  
Linux/Mac:
```bash
source .venv/bin/activate
```
Windows:
```bash
.venv\Scripts\activate
```

*Instalar dependÃªncias:*
```bash
pip install -r requirements.txt
```

*Iniciar a interface web:*
```bash
streamlit run app/streamlit_app.py
```
Acesse no navegador: **http://localhost:8501**


### ğŸ³ 2) Rodar com Docker

Criar imagem:
```bash
docker build -t detector-plagio-parafrase .
```

Executar container:
```bash
docker run --rm -p 8501:8501 detector-plagio-parafrase
```
Acesse no navegador: **http://localhost:8501**

---

## ğŸ–¥ï¸ Como usar a interface

1. Abra o navegador e acesse **http://localhost:8501** (tanto no modo local quanto no Docker).  
2. Na pÃ¡gina inicial, vocÃª verÃ¡:
   - Um campo de texto **"Cole o texto para anÃ¡lise"**.
   - Um botÃ£o **"Comparar"**.
3. Cole o texto que deseja analisar no campo indicado.  
4. Clique em **Comparar** para iniciar a anÃ¡lise.  
5. A pÃ¡gina exibirÃ¡:
   - **Veredito**: indicando se hÃ¡ plÃ¡gio literal, parÃ¡frase ou nenhum caso detectado, com referÃªncia ao documento base.
   - **Texto analisado com destaques**: trechos em vermelho para plÃ¡gio literal e em amarelo para parÃ¡frase.
6. Para ver mais detalhes, clique no *expander* **"Ver blocos e scores detalhados"**:
   - **Blocos mais suspeitos** â€“ tabela com blocos detectados, documento base, classificaÃ§Ã£o, score final e scores lÃ©xico/semÃ¢ntico brutos.
   - **Mais similares (LÃ©xico)** â€“ ranking dos blocos com maior similaridade lÃ©xica.
   - **Mais similares (SemÃ¢ntico)** â€“ ranking dos blocos com maior similaridade semÃ¢ntica.
7. Use essas tabelas para inspecionar quais partes do texto tiveram maior proximidade com o corpus.

---

## ğŸ’­ Mais sobre o Projeto

## SeleÃ§Ã£o da Base de ComparaÃ§Ã£o

Para compor a base pÃºblica do projeto, optou-se por utilizar textos brutos obtidos da **WikipÃ©dia em portuguÃªs**, por meio de um script automatizado que consulta a API pÃºblica da plataforma.  

O ponto de partida foram temas relacionados aos assuntos das Ãºltimas redaÃ§Ãµes do ENEM â€” como questÃµes sociais, culturais e polÃ­ticas. A partir desses artigos iniciais (*seeds*), o script percorreu links internos para ampliar o conjunto atÃ© atingir aproximadamente 200 documentos (neste caso, 174).  

Essa abordagem garante:  
- **Diversidade temÃ¡tica** e relevÃ¢ncia educacional.  
- **Conformidade legal**, utilizando apenas conteÃºdo de domÃ­nio pÃºblico.  
- **Escopo controlado**, atendendo ao requisito de uma base pequena (100â€“200 textos).

**Exemplos de seeds utilizados:**  
Trabalho domÃ©stico, Trabalho de cuidado, Mulheres no Brasil, Igualdade de gÃªnero, Povos e comunidades tradicionais, Povos indÃ­genas do Brasil, Quilombolas, Registro civil, Cidadania, Direitos humanos no Brasil, Estigma associado Ã s doenÃ§as mentais, SaÃºde mental no Brasil, SuicÃ­dio, DepressÃ£o, DemocratizaÃ§Ã£o do acesso ao cinema, Cinema do Brasil, PolÃ­tica cultural do Brasil, Dados pessoais, Privacidade na Internet, ProteÃ§Ã£o de dados no Brasil, Lei Geral de ProteÃ§Ã£o de Dados, EducaÃ§Ã£o de surdos, LÃ­ngua brasileira de sinais, Acessibilidade, IntolerÃ¢ncia religiosa no Brasil, Liberdade religiosa, ViolÃªncia contra a mulher no Brasil, Lei Maria da Penha, Publicidade infantil, Direito do consumidor no Brasil, Lei Seca, Ãlcool e direÃ§Ã£o, ImigraÃ§Ã£o no Brasil, Refugiados no Brasil, Redes sociais, Cultura digital, DesinformaÃ§Ã£o, Fake news, Democracia no Brasil, ParticipaÃ§Ã£o polÃ­tica, Mobilidade urbana, Meio ambiente no Brasil, Sustentabilidade, Racismo no Brasil, InclusÃ£o social, Desigualdade social no Brasil, EducaÃ§Ã£o no Brasil, Bullying, Trabalho infantil no Brasil, Ã‰tica.

---

## Estrutura do Projeto

```
app/                 
â”œâ”€â”€ data/                
â”‚   â”œâ”€â”€ indexes/
â”‚   â”‚   â”œâ”€â”€ lexical/
â”‚   â”‚   â””â”€â”€ semantic/
â”‚   â””â”€â”€ raw/
â”œâ”€â”€ src/                 
â”‚   â”œâ”€â”€ compare_lexical.py
â”‚   â”œâ”€â”€ compare_semantic.py
â”‚   â”œâ”€â”€ combine_scores.py
â”‚   â”œâ”€â”€ compare_service.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ io_utils.py
â”‚   â”œâ”€â”€ pipeline_build_index.py
â”‚   â””â”€â”€ preprocess.py
â”œâ”€â”€ tests/               
â””â”€â”€ Dockerfile
```
---

## Detalhamento e motivos da organizaÃ§Ã£o

- **app/** â€“ ContÃ©m a interface Streamlit, que permite interaÃ§Ã£o direta com o usuÃ¡rio para envio de textos e visualizaÃ§Ã£o dos resultados. Manter a interface separada da lÃ³gica garante que alteraÃ§Ãµes visuais ou de usabilidade nÃ£o impactem o nÃºcleo de processamento.
  
- **data/** â€“ Estrutura para persistÃªncia de dados:  
  - **raw/** preserva o corpus original para que o pipeline possa ser reexecutado sem depender de fontes externas.  
  - **indexes/lexical/** e **indexes/semantic/** guardam Ã­ndices prontos, evitando recomputaÃ§Ãµes custosas e acelerando a inicializaÃ§Ã£o, especialmente em ambientes Docker.
  
- **src/** â€“ CÃ³digo-fonte principal, modularizado para facilitar manutenÃ§Ã£o, testes e substituiÃ§Ã£o de componentes:
  - **`compare_lexical.py`** â€“ Implementa a comparaÃ§Ã£o lÃ©xica com TF-IDF e similaridade do cosseno sobre janelas de texto, buscando rapidez e interpretabilidade.
  - **`compare_semantic.py`** â€“ Executa a comparaÃ§Ã£o semÃ¢ntica usando embeddings normalizados, captando similaridades mesmo quando o vocabulÃ¡rio difere; modelo carregado sob demanda com cache para eficiÃªncia.
  - **`combine_scores.py`** â€“ Une resultados lÃ©xicos e semÃ¢nticos, aplica pesos configurÃ¡veis e thresholds para classificar correspondÃªncias.
  - **`compare_service.py`** â€“ Orquestra o pipeline completo, do fracionamento do texto atÃ© a geraÃ§Ã£o do resultado final estruturado.
  - **`config.py`** â€“ Centraliza parÃ¢metros de configuraÃ§Ã£o, permitindo ajustes por variÃ¡veis de ambiente sem modificar cÃ³digo.
  - **`io_utils.py`** â€“ Padroniza leitura e escrita de dados e Ã­ndices, garantindo compatibilidade entre etapas do pipeline.
  - **`pipeline_build_index.py`** â€“ ResponsÃ¡vel por criar os Ã­ndices a partir do corpus, aplicando janelas deslizantes para aumentar a precisÃ£o das correspondÃªncias.
  - **`preprocess.py`** â€“ Cuida da segmentaÃ§Ã£o de texto, criaÃ§Ã£o de janelas e extensÃ£o de contexto.
  
- **tests/** â€“ ContÃ©m testes unitÃ¡rios e de integraÃ§Ã£o que asseguram a confiabilidade do sistema em cada atualizaÃ§Ã£o.  
- **Dockerfile** â€“ Define um ambiente reprodutÃ­vel, reduzindo diferenÃ§as de comportamento entre mÃ¡quinas locais e pipelines de CI/CD.

---

## PersistÃªncia e Reprodutibilidade

A organizaÃ§Ã£o em `data/` foi projetada para **evitar retrabalho** e permitir reuso eficiente dos resultados mais custosos (Ã­ndices lÃ©xicos e semÃ¢nticos).  
Essa persistÃªncia garante inicializaÃ§Ã£o rÃ¡pida e resultados idÃªnticos, seja em execuÃ§Ã£o local ou via Docker.

---

## Testes Automatizados

Os testes seguem princÃ­pios de **isolamento**, **eficiÃªncia** e **clareza semÃ¢ntica**:  
- ExecuÃ§Ã£o determinÃ­stica, sem dependÃªncias externas.  
- Uso de *mocks* para simular partes pesadas do processamento.  
- Tempo de execuÃ§Ã£o reduzido, viabilizando integraÃ§Ã£o contÃ­nua.

**Cobertura por mÃ³dulo:**  
- `compare_lexical` / `compare_semantic` â€“ Verificam cÃ¡lculos de similaridade e ranqueamento, inclusive com entradas vazias.  
- `combine_scores` â€“ Testa a fusÃ£o ponderada de scores e aplicaÃ§Ã£o correta das classificaÃ§Ãµes.  
- `pipeline_build_index` / `io_utils` â€“ Garante que a indexaÃ§Ã£o e a persistÃªncia sejam reprodutÃ­veis e seguras.  
- `preprocess` â€“ Valida segmentaÃ§Ã£o e manipulaÃ§Ã£o de janelas, incluindo casos de borda.  
- `config` â€“ Testa a leitura de parÃ¢metros e preservaÃ§Ã£o de valores padrÃ£o.  
- `compare_service` â€“ Avalia a integraÃ§Ã£o de todas as etapas e a estrutura final do retorno.

O **GitHub Actions** executa automaticamente toda a suÃ­te de testes a cada push, bloqueando implantaÃ§Ãµes se houver falhas.

---

## OtimizaÃ§Ã£o da Imagem Docker

Para manter a imagem leve e rÃ¡pida:  
- **`python:3.11-slim`** â€“ Reduz significativamente o tamanho em relaÃ§Ã£o Ã  imagem padrÃ£o.  
- **Build multiestÃ¡gio** â€“ Ferramentas de compilaÃ§Ã£o ficam apenas no estÃ¡gio de build.  
- **InstalaÃ§Ã£o mÃ­nima** â€“ Uso de `--no-install-recommends` e limpeza do cache do `apt`.  
- **PyTorch CPU-only** â€“ Elimina dependÃªncias de GPU, reduzindo peso e complexidade.  
- **Sem modelos embutidos** â€“ O modelo Ã© baixado no primeiro uso.  
- **VariÃ¡veis otimizadas** â€“ `PIP_NO_CACHE_DIR=1` e `HF_HOME` configurado para cache previsÃ­vel.

---

## Interface com Streamlit

O arquivo `app/streamlit_app.py` implementa a interface para envio de textos e visualizaÃ§Ã£o dos resultados:  
- Destaques visuais para plÃ¡gio literal e parÃ¡frase.  
- Tabelas com scores e mÃ©tricas detalhadas.  
- Contexto diretamente no texto analisado.  
