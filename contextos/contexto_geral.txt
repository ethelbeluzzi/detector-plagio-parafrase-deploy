# Detector de Plágio e Paráfrase

Este projeto implementa um sistema para **comparar textos** por duas abordagens complementares:  
- **Léxica** – análise baseada em padrões de palavras (TF-IDF e n-gramas).  
- **Semântica** – análise baseada no significado (embeddings com `sentence-transformers`).  

O objetivo é combinar essas análises para obter uma avaliação robusta da similaridade textual, útil para detecção de plágio, identificação de paráfrases e comparação de conteúdos de domínio público.  

O projeto foi pensado para rodar **tanto localmente quanto via Docker**, garantindo que o ambiente seja reprodutível e que os resultados sejam consistentes.

---

## Estrutura do Projeto

```
app/                 
├── data/                
│   ├── indexes/
│   │   ├── lexical/
│   │   └── semantic/
│   └── raw/
├── src/                 
│   ├── compare_lexical.py
│   ├── compare_semantic.py
│   ├── combine_scores.py
│   ├── compare_service.py
│   ├── config.py
│   ├── io_utils.py
│   ├── pipeline_build_index.py
│   └── preprocess.py
├── tests/               
└── Dockerfile
```
---

## Detalhamento e motivos da organização

- **app/** – Contém a interface Streamlit, que permite interação direta com o usuário para envio de textos e visualização dos resultados. Manter a interface separada da lógica garante que alterações visuais ou de usabilidade não impactem o núcleo de processamento.
  
- **data/** – Estrutura para persistência de dados:  
  - **raw/** preserva o corpus original para que o pipeline possa ser reexecutado sem depender de fontes externas.  
  - **indexes/lexical/** e **indexes/semantic/** guardam índices prontos, evitando recomputações custosas e acelerando a inicialização, especialmente em ambientes Docker.
  
- **src/** – Código-fonte principal, modularizado para facilitar manutenção, testes e substituição de componentes:
  - **`compare_lexical.py`** – Implementa a comparação léxica com TF-IDF e similaridade do cosseno sobre janelas de texto, buscando rapidez e interpretabilidade.
  - **`compare_semantic.py`** – Executa a comparação semântica usando embeddings normalizados, captando similaridades mesmo quando o vocabulário difere; modelo carregado sob demanda com cache para eficiência.
  - **`combine_scores.py`** – Une resultados léxicos e semânticos, aplica pesos configuráveis e thresholds para classificar correspondências.
  - **`compare_service.py`** – Orquestra o pipeline completo, do fracionamento do texto até a geração do resultado final estruturado.
  - **`config.py`** – Centraliza parâmetros de configuração, permitindo ajustes por variáveis de ambiente sem modificar código.
  - **`io_utils.py`** – Padroniza leitura e escrita de dados e índices, garantindo compatibilidade entre etapas do pipeline.
  - **`pipeline_build_index.py`** – Responsável por criar os índices a partir do corpus, aplicando janelas deslizantes para aumentar a precisão das correspondências.
  - **`preprocess.py`** – Cuida da segmentação de texto, criação de janelas e extensão de contexto.
  
- **tests/** – Contém testes unitários e de integração que asseguram a confiabilidade do sistema em cada atualização.  
- **Dockerfile** – Define um ambiente reprodutível, reduzindo diferenças de comportamento entre máquinas locais e pipelines de CI/CD.

---
